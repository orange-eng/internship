# my daily


## 20217/1

今天百度实习的组会。一位是语言学背景的，介绍了语言模型linguistic model。在英语中存在很多语法现象，比如主谓一致等等，但是在机器看来，如果有时候定语从句比较长，那么干扰性极强，准确率很低。

易错的语言规则主要有 subject-verb agreement, negative polarity item, garden-path sentences, center-embedding。好文章还有：LSTMs and syntax dependency等等。

另外，对SG score delta没有很理解。

第二位，介绍了有关模型可解释性的问题。比如一个二分类问题，其实就是两种 选择，因此比较容易解释。如果一个很深的网络，那么其实很难解释。

在CV界，如何很好地解释图像，其实可以使用语义分割来形容。一个数字“2”，在机器看来如何去理解？其实就是关注几个比较重要的关键点即可。使用可视化工具来展示可解释性，会把一些集中区域进行标注。但是，这里有一个小问题：Dark knowledge指的是机器的理解思路，这个思路也许并不等于人类的理解思路。因此出现了分歧。

可是，“可解释性”如何衡量？实际上非常主观吧。确实是这样，在很多审稿人看来，就认为，和人类的认识方法一致，才算是合理。

第一次组会，看着大家进行激烈的讨论，真的可以学到很多东西鸭。这才是研究院的氛围，要学会融入。
